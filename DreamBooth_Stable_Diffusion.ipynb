{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUTMHZcbYu_c"
      },
      "outputs": [],
      "source": [
        "# ë°›ì„ ìˆ˜ ìžˆëŠ” ì²´í¬í¬ì¸íŠ¸ë“¤\n",
        "PREDEFINED_CHECKPOINTS = {\n",
        "    # NAI leaks\n",
        "    'NAI - animefull-final-pruned': {\n",
        "        'files': [\n",
        "            {\n",
        "                'url': 'https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/animefull-final-pruned.ckpt',\n",
        "                'target': 'nai/animefull-final-pruned.ckpt',\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/animevae.pt',\n",
        "                'target': 'nai/animefull-final-pruned.vae.pt'\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://gist.githubusercontent.com/toriato/ae1f587f4d1e9ee5d0e910c627277930/raw/6019f8782875497f6e5b3e537e30a75df5b64812/animefull-final-pruned.yaml',\n",
        "                'target': 'nai/animefull-final-pruned.yaml'\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    'NAI - animefull-latest': {\n",
        "        'files': [\n",
        "            {\n",
        "                'url': 'https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/animefull-latest.ckpt',\n",
        "                'target': 'nai/animefull-latest.ckpt'\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/animevae.pt',\n",
        "                'target': 'nai/animefull-latest.vae.pt'\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://gist.githubusercontent.com/toriato/ae1f587f4d1e9ee5d0e910c627277930/raw/6019f8782875497f6e5b3e537e30a75df5b64812/animefull-latest.yaml',\n",
        "                'target': 'nai/animefull-latest.yaml'\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    'NAI - animesfw-final-pruned': {\n",
        "        'files': [\n",
        "            {\n",
        "                'url': 'https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/animesfw-final-pruned.ckpt',\n",
        "                'target': 'nai/animesfw-final-pruned.ckpt'\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/animevae.pt',\n",
        "                'target': 'nai/animesfw-final-pruned.vae.pt'\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://gist.github.com/toriato/ae1f587f4d1e9ee5d0e910c627277930/raw/6019f8782875497f6e5b3e537e30a75df5b64812/animesfw-final-pruned.yaml',\n",
        "                'target': 'nai/animesfw-final-pruned.yaml'\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    'NAI - animesfw-latest': {\n",
        "        'files': [\n",
        "            {\n",
        "                'url': 'https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/animesfw-latest.ckpt',\n",
        "                'target': 'nai/animesfw-latest.ckpt'\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/animevae.pt',\n",
        "                'target': 'nai/animesfw-latest.vae.pt'\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://gist.github.com/toriato/ae1f587f4d1e9ee5d0e910c627277930/raw/6019f8782875497f6e5b3e537e30a75df5b64812/animesfw-latest.yaml',\n",
        "                'target': 'nai/animesfw-latest.yaml'\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    # Waifu Diffusion\n",
        "    'Waifu Diffusion 1.3': {\n",
        "        'files': [{\n",
        "            'url': 'https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float16.ckpt',\n",
        "            'args': ['-o', 'wd-v1-3-epoch09-float16.ckpt']\n",
        "        }]\n",
        "    },\n",
        "\n",
        "    # Trinart2\n",
        "    'Trinart Stable Diffusion v2 60,000 Steps': {\n",
        "        'files': [{'url': 'https://huggingface.co/naclbit/trinart_stable_diffusion_v2/resolve/main/trinart2_step60000.ckpt'}]\n",
        "    },\n",
        "    'Trinart Stable Diffusion v2 95,000 Steps': {\n",
        "        'files': [{'url': 'https://huggingface.co/naclbit/trinart_stable_diffusion_v2/resolve/main/trinart2_step95000.ckpt'}]\n",
        "    },\n",
        "    'Trinart Stable Diffusion v2 115,000 Steps': {\n",
        "        'files': [{'url': 'https://huggingface.co/naclbit/trinart_stable_diffusion_v2/resolve/main/trinart2_step115000.ckpt'}]\n",
        "    },\n",
        "\n",
        "    'Furry (epoch 4)': {\n",
        "        'files': [{'url': 'https://iwiftp.yerf.org/Furry/Software/Stable%20Diffusion%20Furry%20Finetune%20Models/Finetune%20models/furry_epoch4.ckpt'}]\n",
        "    },\n",
        "    'Zack3D Kinky v1': {\n",
        "        'files': [{'url': 'https://iwiftp.yerf.org/Furry/Software/Stable%20Diffusion%20Furry%20Finetune%20Models/Finetune%20models/Zack3D_Kinky-v1.ckpt'}]\n",
        "    },\n",
        "    'Pokemon': {\n",
        "        'files': [{\n",
        "            'url': 'https://huggingface.co/justinpinkney/pokemon-stable-diffusion/resolve/main/ema-only-epoch%3D000142.ckpt',\n",
        "            'args': ['-o', 'pokemon-ema-pruned.ckpt']\n",
        "        }]\n",
        "    },\n",
        "    'Dreambooth - Hiten': {\n",
        "        'files': [{'url': 'https://huggingface.co/BumblingOrange/Hiten/resolve/main/Hiten%20girl_anime_8k_wallpaper_4k.ckpt'}]\n",
        "    },\n",
        "}\n",
        "\n",
        "# ì¶”ê°€ë¡œ ë°›ì„ ìŠ¤í¬ë¦½íŠ¸ë“¤\n",
        "PREDEFINED_SCRIPTS = [\n",
        "    # Advanced prompt matrix\n",
        "    # https://github.com/GRMrGecko/stable-diffusion-webui-automatic/blob/advanced_matrix/scripts/advanced_prompt_matrix.py\n",
        "    lambda: download(\n",
        "        'https://raw.githubusercontent.com/GRMrGecko/stable-diffusion-webui-automatic/advanced_matrix/scripts/advanced_prompt_matrix.py',\n",
        "        'repository/scripts'\n",
        "    ),\n",
        "\n",
        "    # txt2mask\n",
        "    # https://github.com/ThereforeGames/txt2mask\n",
        "    [\n",
        "        lambda: shutil.rmtree(TEMP_DIR, ignore_errors=True),\n",
        "        lambda: execute(\n",
        "            ['git', 'clone', 'https://github.com/ThereforeGames/txt2mask.git', TEMP_DIR],\n",
        "            hide_summary=True\n",
        "        ),\n",
        "        lambda: shutil.rmtree('repository/repositories/clipseg', ignore_errors=True),\n",
        "        lambda: shutil.copytree(os.path.join(TEMP_DIR, 'repositories/clipseg'), 'repository/repositories/clipseg'),\n",
        "        lambda: shutil.copy(os.path.join(TEMP_DIR, 'scripts/txt2mask.py'), 'repository/scripts'),\n",
        "        lambda: shutil.rmtree(TEMP_DIR, ignore_errors=True),\n",
        "    ],\n",
        "\n",
        "    # Img2img Video\n",
        "    # https://github.com/memes-forever/Stable-diffusion-webui-video\n",
        "    lambda: download(\n",
        "        'https://raw.githubusercontent.com/memes-forever/Stable-diffusion-webui-video/main/videos.py',\n",
        "        'repository/scripts'\n",
        "    ),\n",
        "\n",
        "    # Seed Travel\n",
        "    # https://github.com/yownas/seed_travel\n",
        "    [\n",
        "        lambda: None if has_python_package('moviepy') else execute(['pip', 'install', 'moviepy']),\n",
        "        lambda: download(\n",
        "            'https://raw.githubusercontent.com/yownas/seed_travel/main/scripts/seed_travel.py',\n",
        "            'repository/scripts',\n",
        "        )\n",
        "    ],\n",
        "\n",
        "    # Animator\n",
        "    # https://github.com/Animator-Anon/Animator\n",
        "    lambda: download(\n",
        "        'https://raw.githubusercontent.com/Animator-Anon/Animator/main/animation.py',\n",
        "        'repository/scripts'\n",
        "    ),\n",
        "\n",
        "    # Alternate Noise Schedules\n",
        "    # https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts#alternate-noise-schedules\n",
        "    lambda: download(\n",
        "        'https://gist.githubusercontent.com/dfaker/f88aa62e3a14b559fe4e5f6b345db664/raw/791dabfa0ab26399aa2635bcbc1cf6267aa4ffc2/alternate_sampler_noise_schedules.py',\n",
        "        'repository/scripts'\n",
        "    ),\n",
        "\n",
        "    # Vid2Vid\n",
        "    # https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts#vid2vid\n",
        "    lambda: download(\n",
        "        'https://raw.githubusercontent.com/Filarius/stable-diffusion-webui/master/scripts/vid2vid.py',\n",
        "        'repository/scripts'\n",
        "    ),\n",
        "\n",
        "    # Shift Attention\n",
        "    # https://github.com/yownas/shift-attention\n",
        "    [\n",
        "        lambda: None if has_python_package('moviepy') else execute(['pip', 'install', 'moviepy']),\n",
        "        lambda: download(\n",
        "            'https://raw.githubusercontent.com/yownas/shift-attention/main/scripts/shift_attention.py',\n",
        "            'repository/scripts'\n",
        "        )\n",
        "    ],\n",
        "\n",
        "    # Loopback and Superimpose\n",
        "    # https://github.com/DiceOwl/StableDiffusionStuff\n",
        "    lambda: download(\n",
        "        'https://raw.githubusercontent.com/DiceOwl/StableDiffusionStuff/main/loopback_superimpose.py',\n",
        "        'repository/scripts'\n",
        "    ),\n",
        "\n",
        "    # Run n times\n",
        "    # https://gist.github.com/camenduru/9ec5f8141db9902e375967e93250860f\n",
        "    lambda: download(\n",
        "        'https://gist.githubusercontent.com/camenduru/9ec5f8141db9902e375967e93250860f/raw/b5c741676c5514105b9a1ea7dd438ca83802f16f/run_n_times.py',\n",
        "        'repository/scripts'\n",
        "    ),\n",
        "\n",
        "    # Advanced Loopback\n",
        "    # https://github.com/Extraltodeus/advanced-loopback-for-sd-webui\n",
        "    lambda: download(\n",
        "        'https://raw.githubusercontent.com/Extraltodeus/advanced-loopback-for-sd-webui/main/advanced_loopback.py',\n",
        "        'repository/scripts'\n",
        "    ),\n",
        "\n",
        "    # prompt-morph\n",
        "    # https://github.com/feffy380/prompt-morph\n",
        "    [\n",
        "        lambda: None if has_python_package('moviepy') else execute(['pip', 'install', 'moviepy']),\n",
        "        lambda: download(\n",
        "            'https://raw.githubusercontent.com/feffy380/prompt-morph/master/prompt_morph.py',\n",
        "            'repository/scripts'\n",
        "        ),\n",
        "    ],\n",
        "\n",
        "    # prompt interpolation\n",
        "    # https://github.com/EugeoSynthesisThirtyTwo/prompt-interpolation-script-for-sd-webui\n",
        "    lambda: download(\n",
        "        'https://raw.githubusercontent.com/EugeoSynthesisThirtyTwo/prompt-interpolation-script-for-sd-webui/main/prompt_interpolation.py',\n",
        "        'repository/scripts'\n",
        "    ),\n",
        "\n",
        "    # Asymmetric Tiling\n",
        "    # https://github.com/tjm35/asymmetric-tiling-sd-webui/\n",
        "    lambda: download(\n",
        "        'https://raw.githubusercontent.com/tjm35/asymmetric-tiling-sd-webui/main/asymmetric_tiling.py',\n",
        "        'repository/scripts'\n",
        "    ),\n",
        "\n",
        "    # Embedding to PNG\n",
        "    # https://github.com/dfaker/embedding-to-png-script\n",
        "    lambda: download(\n",
        "        'https://raw.githubusercontent.com/dfaker/embedding-to-png-script/main/embedding_to_png.py',\n",
        "        'repository/scripts'\n",
        "    ),\n",
        "]\n",
        "\n",
        "# ì¶”ê°€ë¡œ ë°›ì„ í™•ìž¥ ê¸°ëŠ¥\n",
        "PREDEFINED_EXTENSIONS = [\n",
        "    'https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients.git',\n",
        "    # 'https://github.com/AUTOMATIC1111/stable-diffusion-webui-wildcards.git',\n",
        "    'https://github.com/yfszzx/stable-diffusion-webui-images-browser.git',\n",
        "    'https://github.com/yfszzx/stable-diffusion-webui-inspiration.git',\n",
        "    'https://github.com/tsngo/stable-diffusion-webui-aesthetic-image-scorer',\n",
        "    'https://github.com/Klokinator/UnivAICharGen.git',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XU7NuMAA2drw"
      },
      "outputs": [],
      "source": [
        "#@markdown Check type of GPU and VRAM available.\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzM7j0ZSc_9c"
      },
      "source": [
        "https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnTMyW41cC1E"
      },
      "source": [
        "## Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLWXPZqjsZVV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "try:\n",
        "  USERNAME\n",
        "  PASSWORD\n",
        "except:\n",
        "  USERNAME = input(\"Enter your github ID\")\n",
        "  clear_output()\n",
        "  PASSWORD = input(\"Enter your password\")\n",
        "  clear_output()\n",
        "\n",
        "REPOSITORY = \"stable-diffusion-dreambooth-code-snippets\"\n",
        "GIT_URL = \"https://{}:{}@github.com/{}/{}.git\".format(USERNAME, PASSWORD, USERNAME, REPOSITORY)\n",
        "!git clone $GIT_URL\n",
        "\n",
        "filenames = ['convert_diffusers_to_original_stable_diffusion.py',\n",
        "             'convert_original_stable_diffusion_to_diffusers.py',\n",
        "             'train_dreambooth.py']\n",
        "\n",
        "# !wget -q https://github.com/hikizisa/stable-diffusion-dreambooth-code-snippets/raw/main/train_dreambooth.py\n",
        "# !wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "# !wget -q https://github.com/hikizisa/stable-diffusion-dreambooth-code-snippets/raw/main/convert_original_stable_diffusion_to_diffusers.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsniCOcVa3ml"
      },
      "outputs": [],
      "source": [
        "%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate==0.12.0 transformers ftfy bitsandbytes gradio natsort\n",
        "%pip install -q OmegaConf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y4lqqWT_uxD2"
      },
      "outputs": [],
      "source": [
        "#@title Login to HuggingFace ðŸ¤—\n",
        "\n",
        "#@markdown You need to accept the model license before downloading or using the Stable Diffusion weights. Please, visit the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5), read the license and tick the checkbox if you agree. You have to be a registered user in ðŸ¤— Hugging Face Hub, and you'll also need to use an access token for the code to work.\n",
        "# https://huggingface.co/settings/tokens\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"\" #@param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfTlc8Mqb8iH"
      },
      "source": [
        "### Install xformers from precompiled wheel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6dcjPnnaiCn"
      },
      "outputs": [],
      "source": [
        "%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "# These were compiled on Tesla T4, should also work on P100, thanks to https://github.com/metrolobo\n",
        "\n",
        "# If precompiled wheels don't work, install it with the following command. It will take around 40 minutes to compile.\n",
        "# %pip install git+https://github.com/facebookresearch/xformers@1d31a3a#egg=xformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0NV324ZcL9L"
      },
      "source": [
        "## Settings and run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rxg0y5MBudmd"
      },
      "outputs": [],
      "source": [
        "#@markdown If model weights should be saved directly in google drive (takes around 4-5 GB).\n",
        "save_to_gdrive = True #@param {type:\"boolean\"}\n",
        "if save_to_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "#@markdown Name/Path of the initial model.\n",
        "#kjy1013/test2\n",
        "MODEL_NAME = \"NAI - animefull-final-pruned\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the directory name to save model at.\n",
        "\n",
        "OUTPUT_DIR = \"stable_diffusion_weights/\" #@param {type:\"string\"}\n",
        "SAVE_DIR = \"/content/drive/MyDrive/\" if save_to_gdrive else \"/content\"\n",
        "OUTPUT_DIR = SAVE_DIR + OUTPUT_DIR\n",
        "\n",
        "print(f\"[*] Weights will be saved at {OUTPUT_DIR}\")\n",
        "\n",
        "!mkdir -p $OUTPUT_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcB2g39AWRzk"
      },
      "source": [
        "## Convert Model from ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q0X7eAsWZFP",
        "outputId": "56691480-f6e4-426b-ad2e-e3919fd546ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imefull-final-prune  99%[==================> ]   3.95G  27.0MB/s    eta 1s     "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        " # https://self-development.info/%E3%80%90stable-diffusion%E3%80%91ckpt%E3%82%92diffusers%E3%81%A7%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%82%80/\n",
        "\n",
        "BASE_PATH = '/content/models'\n",
        "\n",
        "if MODEL_NAME in PREDEFINED_CHECKPOINTS:\n",
        "  YAML_URL = PREDEFINED_CHECKPOINTS[MODEL_NAME]['files'][2]['url']\n",
        "  YAML_REALNAME = PREDEFINED_CHECKPOINTS[MODEL_NAME]['files'][2]['target'].split('/')[-1]\n",
        "  YAML_PATH = os.path.join(BASE_PATH, YAML_REALNAME)\n",
        "  CKPT_URL = PREDEFINED_CHECKPOINTS[MODEL_NAME]['files'][0]['url']\n",
        "  CKPT_REALNAME = PREDEFINED_CHECKPOINTS[MODEL_NAME]['files'][0]['target'].split('/')[-1]\n",
        "  CKPT_PATH = os.path.join(BASE_PATH, CKPT_REALNAME)\n",
        "\n",
        "  if not os.path.isfile(YAML_PATH):\n",
        "    !wget -P $BASE_PATH $YAML_URL\n",
        "  if not os.path.isfile(CKPT_PATH):\n",
        "    !wget -P $BASE_PATH $CKPT_URL\n",
        "\n",
        "  MODEL_NAME = os.path.join (BASE_PATH, \"\".join(x for x in MODEL_NAME if x.isalnum()))\n",
        "  !python /content/$REPOSITORY/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $CKPT_PATH --dump_path $MODEL_NAME --original_config_file $YAML_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn5ILIyDJIcX"
      },
      "source": [
        "# Start Training\n",
        "\n",
        "Use the table below to choose the best flags based on your memory and speed requirements. Tested on Tesla T4 GPU.\n",
        "\n",
        "\n",
        "| `fp16` | `train_batch_size` | `gradient_accumulation_steps` | `gradient_checkpointing` | `use_8bit_adam` | GB VRAM usage | Speed (it/s) |\n",
        "| ---- | ------------------ | ----------------------------- | ----------------------- | --------------- | ---------- | ------------ |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | TRUE            | 9.92       | 0.93         |\n",
        "| no   | 1                  | 1                             | TRUE                    | TRUE            | 10.08      | 0.42         |\n",
        "| fp16 | 2                  | 1                             | TRUE                    | TRUE            | 10.4       | 0.66         |\n",
        "| fp16 | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 1.14         |\n",
        "| no   | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 0.49         |\n",
        "| fp16 | 1                  | 2                             | TRUE                    | TRUE            | 11.56      | 1            |\n",
        "| fp16 | 2                  | 1                             | FALSE                   | TRUE            | 13.67      | 0.82         |\n",
        "| fp16 | 1                  | 2                             | FALSE                   | TRUE            | 13.7       | 0.83          |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | FALSE           | 15.79      | 0.77         |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ioxxvHoicPs"
      },
      "source": [
        "Add `--gradient_checkpointing` flag for around 9.92 GB VRAM usage.\n",
        "\n",
        "remove `--use_8bit_adam` flag for full precision. Requires 15.79 GB with `--gradient_checkpointing` else 17.8 GB.\n",
        "\n",
        "remove `--train_text_encoder` flag to reduce memory usage further, degrades output quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vDpCxId1aCm"
      },
      "outputs": [],
      "source": [
        "# You can also add multiple concepts here. Try tweaking `--max_train_steps` accordingly.\n",
        "\n",
        "custom_prompt = \"<ktk>\"\n",
        "instance_prompt = \"{}\".format(custom_prompt)\n",
        "concepts_list = [\n",
        "    {\n",
        "        \"instance_prompt\":      instance_prompt,\n",
        "        \"class_prompt\":         instance_prompt.replace(custom_prompt, \"\"),\n",
        "        \"instance_data_dir\":    \"/content/drive/MyDrive/dreambooth/kantoku\",\n",
        "        \"class_data_dir\":       \"/content/drive/MyDrive/dreambooth/girlexp1\"\n",
        "    },\n",
        "#     {\n",
        "#         \"instance_prompt\":      \"photo of ukj person\",\n",
        "#         \"class_prompt\":         \"photo of a person\",\n",
        "#         \"instance_data_dir\":    \"/content/data/ukj\",\n",
        "#         \"class_data_dir\":       \"/content/data/person\"\n",
        "#     }\n",
        "]\n",
        "\n",
        "# `class_data_dir` contains regularization images\n",
        "import json\n",
        "import os\n",
        "#for c in concepts_list:\n",
        "#    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n",
        "\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "32gYIDDR1aCp"
      },
      "outputs": [],
      "source": [
        "#@markdown Upload your images by running this cell.\n",
        "\n",
        "#@markdown OR\n",
        "\n",
        "#@markdown You can use the file manager on the left panel to upload (drag and drop) to each `instance_data_dir` (it uploads faster)\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "for c in concepts_list:\n",
        "    print(f\"Uploading instance images for `{c['instance_prompt']}`\")\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        dst_path = os.path.join(c['instance_data_dir'], filename)\n",
        "        shutil.move(filename, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjcSXTp-u-Eg"
      },
      "outputs": [],
      "source": [
        "!accelerate launch ./$REPOSITORY/train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_DIR \\\n",
        "  --pretrained_vae_name_or_path=\"PurpleFlavorTea/N_VAE\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --seed=1337 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --save_infer_steps=28 \\\n",
        "  --save_guidance_scale=11 \\\n",
        "  --save_sample_negative_prompt=\"low quality, bad anatomy, bad proportion, bad perspective, bad hands, bad feet, bad leg\" \\\n",
        "  --num_class_images=50 \\\n",
        "  --sample_batch_size=4 \\\n",
        "  --max_train_steps=800 \\\n",
        "  --save_interval=10000 \\\n",
        "  --save_sample_prompt=instance_prompt \\\n",
        "  --concepts_list=\"concepts_list.json\" \\\n",
        "\n",
        "# Reduce the `--save_interval` to lower than `--max_train_steps` to save weights from intermediate steps.\n",
        "# `--save_sample_prompt` can be same as `--instance_prompt` to generate intermediate samples (saved along with weights in samples directory)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89Az5NUxOWdy"
      },
      "outputs": [],
      "source": [
        "#@markdown Run to generate a grid of preview images from the last saved weights.\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "weights_folder = OUTPUT_DIR\n",
        "folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\"], key=lambda x: int(x))\n",
        "\n",
        "row = len(folders)\n",
        "col = len(os.listdir(os.path.join(weights_folder, folders[0], \"samples\")))\n",
        "scale = 4\n",
        "fig, axes = plt.subplots(row, col, figsize=(col*scale, row*scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "\n",
        "for i, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(weights_folder, folder)\n",
        "    image_folder = os.path.join(folder_path, \"samples\")\n",
        "    images = [f for f in os.listdir(image_folder)]\n",
        "    for j, image in enumerate(images):\n",
        "        if row == 1:\n",
        "            currAxes = axes[j]\n",
        "        else:\n",
        "            currAxes = axes[i, j]\n",
        "        if i == 0:\n",
        "            currAxes.set_title(f\"Image {j}\")\n",
        "        if j == 0:\n",
        "            currAxes.text(-0.1, 0.5, folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "        image_path = os.path.join(image_folder, image)\n",
        "        img = mpimg.imread(image_path)\n",
        "        currAxes.imshow(img, cmap='gray')\n",
        "        currAxes.axis('off')\n",
        "        \n",
        "plt.tight_layout()\n",
        "plt.savefig('grid.png', dpi=72)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "L6AARsQDMudI"
      },
      "outputs": [],
      "source": [
        "#@markdown Specify the weights directory to use (leave blank for latest)\n",
        "WEIGHTS_DIR = \"\" #@param {type:\"string\"}\n",
        "if WEIGHTS_DIR == \"\":\n",
        "    from natsort import natsorted\n",
        "    from glob import glob\n",
        "    import os\n",
        "    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "print(f\"[*] WEIGHTS_DIR={WEIGHTS_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V8wgU0HN-Kq"
      },
      "source": [
        "## Convert weights to ckpt to use in web UIs like AUTOMATIC1111."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcXzsUyG1aCy"
      },
      "outputs": [],
      "source": [
        "#@markdown Run conversion.\n",
        "ckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n",
        "\n",
        "half_arg = \"\"\n",
        "#@markdown  Whether to convert to fp16, takes half the space (2GB).\n",
        "fp16 = True #@param {type: \"boolean\"}\n",
        "if fp16:\n",
        "    half_arg = \"--half\"\n",
        "!python ./$REPOSITORY/convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg\n",
        "print(f\"[*] Converted ckpt saved at {ckpt_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToNG4fd_dTbF"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW15FjffdTID"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "\n",
        "model_path = WEIGHTS_DIR             # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "\n",
        "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "g_cuda = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oIzkltjpVO_f"
      },
      "outputs": [],
      "source": [
        "#@markdown Can set random seed here for reproducibility.\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "seed = 52362 #@param {type:\"number\"}\n",
        "g_cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K6xoHWSsbcS3",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#@title Run for generating images.\n",
        "\n",
        "prompt = \"best quality, masterpiece, \\u003Cktk>, 1girl,\" #@param {type:\"string\"}\n",
        "negative_prompt = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, artist name\" #@param {type:\"string\"}\n",
        "num_samples = 4 #@param {type:\"number\"}\n",
        "guidance_scale = 11 #@param {type:\"number\"}\n",
        "num_inference_steps = 28 #@param {type:\"number\"}\n",
        "height = 512 #@param {type:\"number\"}\n",
        "width = 512 #@param {type:\"number\"}\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "WMCqQ5Tcdsm2"
      },
      "outputs": [],
      "source": [
        "#@markdown Run Gradio UI for generating images.\n",
        "import gradio as gr\n",
        "\n",
        "def inference(prompt, negative_prompt, num_samples, height=512, width=512, num_inference_steps=50, guidance_scale=7.5):\n",
        "    with torch.autocast(\"cuda\"), torch.inference_mode():\n",
        "        return pipe(\n",
        "                prompt, height=int(height), width=int(width),\n",
        "                negative_prompt=negative_prompt,\n",
        "                num_images_per_prompt=int(num_samples),\n",
        "                num_inference_steps=int(num_inference_steps), guidance_scale=guidance_scale,\n",
        "                generator=g_cuda\n",
        "            ).images\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            prompt = gr.Textbox(label=\"Prompt\", value=\"photo of sks dog in a bucket\")\n",
        "            negative_prompt = gr.Textbox(label=\"Negative Prompt\", value=\"\")\n",
        "            run = gr.Button(value=\"Generate\")\n",
        "            with gr.Row():\n",
        "                num_samples = gr.Number(label=\"Number of Samples\", value=4)\n",
        "                guidance_scale = gr.Number(label=\"Guidance Scale\", value=7.5)\n",
        "            with gr.Row():\n",
        "                height = gr.Number(label=\"Height\", value=512)\n",
        "                width = gr.Number(label=\"Width\", value=512)\n",
        "            num_inference_steps = gr.Slider(label=\"Steps\", value=50)\n",
        "        with gr.Column():\n",
        "            gallery = gr.Gallery()\n",
        "\n",
        "    run.click(inference, inputs=[prompt, negative_prompt, num_samples, height, width, num_inference_steps, guidance_scale], outputs=gallery)\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lJoOgLQHnC8L"
      },
      "outputs": [],
      "source": [
        "#@title (Optional) Delete diffuser and old weights and only keep the ckpt to free up drive space.\n",
        "\n",
        "#@markdown [ ! ] Caution, Only execute if you are sure u want to delete the diffuser format weights and only use the ckpt.\n",
        "import shutil\n",
        "from glob import glob\n",
        "import os\n",
        "for f in glob(OUTPUT_DIR+os.sep+\"*\"):\n",
        "    if f != WEIGHTS_DIR:\n",
        "        shutil.rmtree(f)\n",
        "        print(\"Deleted\", f)\n",
        "for f in glob(WEIGHTS_DIR+\"/*\"):\n",
        "    if not f.endswith(\".ckpt\") or not f.endswith(\".json\"):\n",
        "        try:\n",
        "            shutil.rmtree(f)\n",
        "        except NotADirectoryError:\n",
        "            continue\n",
        "        print(\"Deleted\", f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXgi8HM4c-DA"
      },
      "outputs": [],
      "source": [
        "#@title Free runtime memory\n",
        "exit()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "XfTlc8Mqb8iH"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}